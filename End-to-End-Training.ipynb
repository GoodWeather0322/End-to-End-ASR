{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from kaldiio import ReadHelper\n",
    "import json\n",
    "import os \n",
    "import time\n",
    "from tqdm import notebook\n",
    "import copy\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "espnet_path = Path('espnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egs_path = Path('egs/aishell/asr1')\n",
    "exp_dir = espnet_path / egs_path / 'exp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_path = 'dump'\n",
    "train_path = 'train_sp'\n",
    "dev_path = 'dev'\n",
    "test_path = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = espnet_path / egs_path / 'data/lang_1char/train_sp_units.txt'\n",
    "vocab = {}\n",
    "with open(vocab_file) as fp:\n",
    "    for line in fp:\n",
    "        word, idx = line.strip().split()\n",
    "        vocab[word] = idx\n",
    "        \n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id = 4\n",
    "token2id = {'<blank>':0, '<pad>':1, '<sos>':2, '<eos>':3}\n",
    "for word, _ in vocab.items():\n",
    "    if word not in token2id:\n",
    "        token2id[word] = new_id\n",
    "        new_id += 1\n",
    "\n",
    "id2token = {v:k for k, v in token2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {}\n",
    "dev_data = {}\n",
    "test_data = {}\n",
    "\n",
    "for (set_path, dataset) in zip([train_path, dev_path, test_path], [train_data, dev_data, test_data]):\n",
    "    set_dump_path = espnet_path / egs_path / dump_path / set_path / 'deltafalse' \n",
    "    with open(set_dump_path / 'data.json') as fp:\n",
    "        json_data = json.load(fp)\n",
    "\n",
    "    feats = {}\n",
    "    pbar = notebook.tqdm(total=len(list(set_dump_path.glob('feats.*.ark'))))\n",
    "    for feats_file in set_dump_path.glob('feats.*.ark'):\n",
    "        with ReadHelper('ark:'+str(feats_file)) as reader:\n",
    "            for key, numpy_array in reader:\n",
    "                feats[key] = torch.from_numpy(numpy_array)\n",
    "          \n",
    "        pbar.update(1)\n",
    "        \n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    for key, value in json_data['utts'].items():\n",
    "        if key in feats:\n",
    "            feature = feats[key]\n",
    "            text = json_data['utts'][key]['output'][0]['text']\n",
    "            token = []\n",
    "            token_id = []\n",
    "            for char in text:\n",
    "                if char == ' ':\n",
    "                    token.append('<space>')\n",
    "                else:\n",
    "                    if char in vocab:\n",
    "                        token.append(char)\n",
    "                    else:\n",
    "                        token.append('<unk>')\n",
    "            dataset[key] = {'input':feature,\n",
    "                           'text':text,\n",
    "                           'token':' '.join(token),}\n",
    "        \n",
    "\n",
    "    \n",
    "print(len(train_data), len(dev_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    \"\"\" Access dictionary keys like attribute \n",
    "        https://stackoverflow.com/questions/4984647/accessing-dict-keys-like-an-attribute\n",
    "    \"\"\"\n",
    "    def __init__(self, *av, **kav):\n",
    "        dict.__init__(self, *av, **kav)\n",
    "        self.__dict__ = self\n",
    "\n",
    "opts = AttrDict()\n",
    "\n",
    "# Configure models\n",
    "\n",
    "opts.ntoken = len(token2id)\n",
    "opts.feature = 83\n",
    "opts.ninp = 256\n",
    "opts.nhead = 4\n",
    "opts.nhid = 2048\n",
    "opts.nlayers_enc = 12\n",
    "opts.nlayers_dec = 6\n",
    "\n",
    "opts.ce_weight = 0.7\n",
    "opts.ctc_weight = 0.3\n",
    "\n",
    "opts.beam_size = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Configure optimization\n",
    "opts.learning_rate = 5e-5\n",
    "\n",
    "opts.dropout_rate = 0.1\n",
    "\n",
    "opts.batch_size = 64\n",
    "opts.num_workers = int(opts.batch_size / 8) if int(opts.batch_size / 8) < 16 else 16\n",
    "print(opts.num_workers)\n",
    "# Configure training\n",
    "opts.max_seq_len = 512\n",
    "opts.num_epochs = 300\n",
    "# opts.warmup_steps = 4000\n",
    "# opts.gradient_accumulation = 20\n",
    "\n",
    "# opts.load_pretrain = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        \n",
    "        self.names = []\n",
    "        self.features = []\n",
    "        self.texts = []\n",
    "        self.tokens = []\n",
    "        \n",
    "        for name, data in dataset.items():\n",
    "            feature = data['input']\n",
    "            text = data['text']\n",
    "            token = data['token'].split(' ')\n",
    "            token = ['<sos>'] + token + ['<eos>']\n",
    "            \n",
    "            self.names.append(name)\n",
    "            self.features.append(feature)\n",
    "            self.texts.append(text)\n",
    "            self.tokens.append(token)\n",
    "            \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.names)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        name = self.names[index]\n",
    "        feature = self.features[index]\n",
    "        text = self.texts[index]\n",
    "        token = self.tokens[index]\n",
    "        token_id = self.tokens2ids(token, token2id)\n",
    "        \n",
    "        return name, feature, text, token, token_id\n",
    "    \n",
    "    def tokens2ids(self, tokens, token2id):\n",
    "        token_id = [token2id[token] if token in token2id else token2id['<unk>'] for token in tokens]\n",
    "    \n",
    "        return token_id\n",
    "    \n",
    "    \n",
    "def collate_fn(data):\n",
    "    \n",
    "    def _pad_sequences(seqs):\n",
    "        lens = [len(seq)-1 for seq in seqs]\n",
    "        input_seqs = torch.zeros(len(seqs), max(lens)).long().fill_(token2id['<pad>'])\n",
    "        target_seqs = torch.zeros(len(seqs), max(lens)).long().fill_(token2id['<pad>'])\n",
    "#         input_seqs_mask = input_seqs.float().masked_fill(input_seqs.float()==0, float('-inf'))\n",
    "#         input_seqs_mask = input_seqs_mask.masked_fill(input_seqs_mask!=float('-inf'), 0)\n",
    "\n",
    "        for i, seq in enumerate(seqs):\n",
    "            input_seqs[i, :len(seq)-1] = torch.LongTensor(seq[:-1])\n",
    "            target_seqs[i, :len(seq)-1] = torch.LongTensor(seq[1:])\n",
    "            \n",
    "        input_seqs_mask = input_seqs == token2id['<pad>']\n",
    "        \n",
    "        return input_seqs, input_seqs_mask, target_seqs, lens\n",
    "    \n",
    "    def _pad_features(features):\n",
    "        flens = [len(feature) for feature in features]\n",
    "        input_features = torch.zeros(len(features), max(flens), opts.feature)\n",
    "        for i, feature in enumerate(features):\n",
    "            input_features[i, :len(feature)] = feature\n",
    "            \n",
    "        return input_features\n",
    "    \n",
    "    def _generate_square_subsequent_mask(sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "        \n",
    "    \n",
    "    name, feature, text, token, token_id = zip(*data)\n",
    "    \n",
    "    input_seqs, input_seqs_pad_mask, target_seqs, lens = _pad_sequences(token_id)\n",
    "    \n",
    "    input_features = _pad_features(feature)\n",
    "    \n",
    "    input_seqs_mask = _generate_square_subsequent_mask(input_seqs.size(1))\n",
    "    input_seqs_mask = input_seqs_mask.repeat(input_seqs.size(0), 1, 1) #為了給dataparallel切 要給他一個batch維\n",
    "    \n",
    "    lens = torch.LongTensor(lens)\n",
    "    \n",
    "    return name, input_features, text, token, input_seqs, input_seqs_mask, input_seqs_pad_mask, target_seqs, lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_data)\n",
    "dev_dataset = Dataset(dev_data)\n",
    "test_dataset = Dataset(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dev_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20200915)\n",
    "torch.manual_seed(20200915)\n",
    "torch.cuda.manual_seed_all(20200915)\n",
    "\n",
    "train_iter = DataLoader(dataset=train_dataset,\n",
    "                        batch_size=opts.batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=opts.num_workers,\n",
    "                        collate_fn=collate_fn)\n",
    "\n",
    "dev_iter = DataLoader(dataset=dev_dataset,\n",
    "                        batch_size=opts.batch_size,\n",
    "                        shuffle=False,\n",
    "                        num_workers=opts.num_workers,\n",
    "                        collate_fn=collate_fn)\n",
    "\n",
    "test_iter = DataLoader(dataset=test_dataset,\n",
    "                        batch_size=opts.batch_size,\n",
    "                        shuffle=False,\n",
    "                        num_workers=opts.num_workers,\n",
    "                        collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dSubsampling(torch.nn.Module):\n",
    "    \"\"\"Convolutional 2D subsampling (to 1/4 length).\n",
    "    :param int idim: input dim\n",
    "    :param int odim: output dim\n",
    "    :param flaot dropout_rate: dropout rate\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, idim, odim, dropout_rate=0.5):\n",
    "        \"\"\"Construct an Conv2dSubsampling object.\"\"\"\n",
    "        super(Conv2dSubsampling, self).__init__()\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, odim, 3, 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(odim, odim, 3, 2),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.out = torch.nn.Sequential(\n",
    "            torch.nn.Linear(odim * (((idim - 1) // 2 - 1) // 2), odim),\n",
    "#             PositionalEncoding(odim, dropout_rate),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, x_mask):\n",
    "        \"\"\"Subsample x.\n",
    "        :param torch.Tensor x: input tensor\n",
    "        :param torch.Tensor x_mask: input mask\n",
    "        :return: subsampled x and mask\n",
    "        :rtype Tuple[torch.Tensor, torch.Tensor]\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(1)  # (b, c, t, f)\n",
    "        x = self.conv(x)\n",
    "        b, c, t, f = x.size()\n",
    "        x = self.out(x.transpose(1, 2).contiguous().view(b, t, c * f))\n",
    "        if x_mask is None:\n",
    "            return x, None\n",
    "        return x, x_mask[:, :, :-2:2][:, :, :-2:2]\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class EncoderModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, idim, dropout=0.5):\n",
    "        super(EncoderModel, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.embedding = Conv2dSubsampling(idim, ninp)\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.ninp = ninp\n",
    "#         self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "#         self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "#         self.decoder.bias.data.zero_()\n",
    "#         self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        \n",
    "        # src [b, t, f]        \n",
    "        \n",
    "        src, self.src_mask = self.embedding(src, self.src_mask)\n",
    "\n",
    "        src = src.permute(1, 0, 2) # [t, b, f]\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src=src, \n",
    "                                          mask=self.src_mask,\n",
    "                                         )\n",
    "#         output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "class DecoderModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(DecoderModel, self).__init__()\n",
    "        from torch.nn import TransformerDecoder, TransformerDecoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.tgt_mask = None\n",
    "        self.memory_mask = None\n",
    "        self.embedding = nn.Embedding(ntoken, ninp)\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        decoder_layers = TransformerDecoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layers, nlayers)\n",
    "        self.ninp = ninp\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    def forward(self, tgt, tgt_mask, tgt_key_padding_mask, memory):\n",
    "        \n",
    "        # tgt [b, t], tgt_key_padding_mask [b, t], memory [t, b, f]\n",
    "        \n",
    "        tgt = tgt.permute(1, 0) # [t, b]\n",
    "        \n",
    "#         if self.tgt_mask is None or self.tgt_mask.size(0) != len(tgt):\n",
    "#             device = tgt.device\n",
    "#             mask = self._generate_square_subsequent_mask(len(tgt)).to(device)\n",
    "#             self.tgt_mask = mask\n",
    "\n",
    "        # The reason we increase the embedding values before the addition \n",
    "        # is to make the positional encoding relatively smaller. \n",
    "        # This means the original meaning \n",
    "        # in the embedding vector won’t be lost when we add them together.\n",
    "        # maybe use learned position embedding will not need to do this?  \n",
    "        \n",
    "        tgt = self.embedding(tgt) * math.sqrt(self.ninp)\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "        \n",
    "        tgt_mask = tgt_mask[0] ##為了dataparallel給的batch維把它去掉\n",
    "        \n",
    "        output = self.transformer_decoder(tgt, memory, \n",
    "                                          tgt_mask=tgt_mask, \n",
    "                                          tgt_key_padding_mask=tgt_key_padding_mask, \n",
    "                                          memory_mask=self.memory_mask, \n",
    "                                          memory_key_padding_mask=None,\n",
    "                                          )\n",
    "        return output\n",
    "        \n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers_enc, nlayers_dec, idim, dropout=0.5):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.encoder = EncoderModel(ntoken, ninp, nhead, nhid, nlayers_enc, idim, dropout)\n",
    "        self.ctc_classifier = nn.Linear(ninp, ntoken)\n",
    "        \n",
    "        self.decoder = DecoderModel(ntoken, ninp, nhead, nhid, nlayers_dec, dropout)\n",
    "        self.classifier = nn.Linear(ninp, ntoken)\n",
    "        \n",
    "    def forward(self, src, tgt, tgt_mask, tgt_key_padding_mask):\n",
    "        \n",
    "        memory = self.encoder(src)\n",
    "        \n",
    "        ctc_output = self.ctc_classifier(memory.permute(1, 0, 2))\n",
    "        \n",
    "        decoder_output = self.decoder(tgt, tgt_mask, tgt_key_padding_mask, memory)\n",
    "        \n",
    "        output = self.classifier(decoder_output.permute(1, 0, 2))\n",
    "\n",
    "        # return 一定要batch first 不然dataparallel會concat錯維\n",
    "        return ctc_output, output, memory.permute(1, 0, 2), decoder_output.permute(1, 0, 2)\n",
    "#         return memory, ctc_output, decoder_output\n",
    "\n",
    "\n",
    "class Test_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers_enc, nlayers_dec, idim, dropout=0.5):\n",
    "        super(Test_Model, self).__init__()\n",
    "        \n",
    "        self.encoder = EncoderModel(ntoken, ninp, nhead, nhid, nlayers_enc, idim, dropout)\n",
    "        self.ctc_classifier = nn.Linear(ninp, ntoken)\n",
    "        \n",
    "        self.decoder = DecoderModel(ntoken, ninp, nhead, nhid, nlayers_dec, dropout)\n",
    "        self.classifier = nn.Linear(ninp, ntoken)\n",
    "        \n",
    "        self.encoder.eval()\n",
    "        self.ctc_classifier.eval()\n",
    "        self.decoder.eval()\n",
    "        self.classifier.eval()\n",
    "        \n",
    "    def forward(self, src, len_limit):\n",
    "        \n",
    "        device = src.device\n",
    "        memory = self.encoder(src)\n",
    "        \n",
    "        nbest = []\n",
    "        beams = []\n",
    "        beams.append([[token2id['<sos>']], 0])\n",
    "\n",
    "        for _ in range(2*len_limit):\n",
    "\n",
    "            results = []\n",
    "\n",
    "            for beam in beams:\n",
    "\n",
    "                input_idxs = beam[0]\n",
    "\n",
    "                input_seqs = torch.LongTensor([input_idxs])\n",
    "        #         input_seqs = input_seqs.unsqueeze(0)\n",
    "                input_seqs = input_seqs.to(device)\n",
    "\n",
    "                decoder_output = self.decoder(input_seqs, None, memory)\n",
    "                output = self.classifier(decoder_output.permute(1, 0, 2)[:, -1])\n",
    "                output = output.log_softmax(dim=1)\n",
    "                output[:, 0] = float('-inf')\n",
    "                probs, idxs = output.topk(k=opts.beam_size, dim=1)\n",
    "\n",
    "                for prob, idx in zip(probs.squeeze(0), idxs.squeeze(0)):\n",
    "\n",
    "                    generate_idxs = input_idxs + [idx.item()]\n",
    "                    accumulate_prob = beam[1] + prob.item()\n",
    "\n",
    "                    results.append([generate_idxs, accumulate_prob])\n",
    "\n",
    "\n",
    "            results.sort(key=lambda x:x[1])\n",
    "            results = results[::-1]\n",
    "            results = results[:3]\n",
    "\n",
    "            beams = []\n",
    "\n",
    "            for result in results:\n",
    "                if result[0][-1] == token2id['<eos>']:\n",
    "                    nbest.append(result)\n",
    "                else:\n",
    "                    beams.append(result)\n",
    "\n",
    "        return nbest, beams\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exp_dir)\n",
    "\n",
    "RESTORE = False\n",
    "\n",
    "LOAD_RNNLM = False\n",
    "\n",
    "if RESTORE:\n",
    "    experiment_dir = Path(exp_dir) / 'tedr2_rnnlm_1stlayer_BERT_EN_finetune_increment_hidden300_len35_2020-01-01 11:15:21'\n",
    "    last_epoch = 29\n",
    "    print(experiment_dir)\n",
    "    \n",
    "else:\n",
    "\n",
    "    if LOAD_RNNLM:\n",
    "        experiment_name = 'rnnlm_dictALL_talk-sent_len130_2019-11-09 14:53:52'\n",
    "        experiment_dir = Path(exp_dir) / experiment_name\n",
    "        model_dir = experiment_dir / 'best_model'\n",
    "        print(model_dir)\n",
    "\n",
    "    last_epoch = -1\n",
    "    model_name = 'myaishell_ce{}_ctc{}'.format(\\\n",
    "                                   opts.ce_weight, opts.ctc_weight)\n",
    "    now = str(datetime.now()).split('.')[0]\n",
    "    experiment_name = '{}_{}'.format(model_name, now)\n",
    "    experiment_dir = Path(exp_dir) / experiment_name\n",
    "    experiment_dir.mkdir(exist_ok=True, parents=True)\n",
    "    print(experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_trainlog = experiment_dir / 'train_log.txt'\n",
    "\n",
    "def log2file(log_file, msg):\n",
    "    with open(log_file, 'a') as fw:\n",
    "        fw.write(msg)\n",
    "        fw.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(opts.ntoken, opts.ninp, opts.nhead, opts.nhid, opts.nlayers_enc, opts.nlayers_dec, opts.feature, opts.dropout_rate)\n",
    "\n",
    "print('total parms : ', sum(p.numel() for p in model.parameters()))\n",
    "print('trainable parms : ', sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "# USE_CUDA = False\n",
    "\n",
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model)\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=opts.learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=opts.learning_rate, steps_per_epoch=len(train_iter), epochs=20)\n",
    "\n",
    "# ce_criterion = torch.nn.KLDivLoss()\n",
    "ce_criterion = torch.nn.CrossEntropyLoss(reduction='mean', ignore_index=token2id['<pad>'])\n",
    "ctc_criterion = torch.nn.CTCLoss(reduction='mean', blank=token2id['<blank>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_epoch = -1\n",
    "\n",
    "for k,v in opts.items():\n",
    "    log_msg = '- {}: {}'.format(k, v)\n",
    "    log2file(str(experiment_trainlog), log_msg)\n",
    "    print(log_msg)\n",
    "\n",
    "pbar_train = notebook.tqdm(total=len(train_iter))\n",
    "pbar_dev = notebook.tqdm(total=len(dev_iter))\n",
    "pbar_test = notebook.tqdm(total=len(test_iter))\n",
    "\n",
    "log_msg = '='*50\n",
    "print(log_msg)\n",
    "log2file(str(experiment_trainlog), log_msg)\n",
    "log_msg = 'optim : \\n' + str(optimizer)\n",
    "print(log_msg)   \n",
    "log2file(str(experiment_trainlog), log_msg)\n",
    "\n",
    "for epoch in range(last_epoch+1,  opts.num_epochs, 1):\n",
    "    \n",
    "    pbar_train.reset()\n",
    "    pbar_dev.reset()\n",
    "    pbar_test.reset()\n",
    "    \n",
    "    loss_tracker = []\n",
    "    celoss_tracker = []\n",
    "    ctcloss_tracker = []\n",
    "    time_tracker = []\n",
    "    time_tracker.append(time.time())\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for iteration, batch in enumerate(train_iter):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        name, input_features, text, token, input_seqs, input_seqs_mask, input_seqs_pad_mask, target_seqs, lens = batch\n",
    "        \n",
    "        batch_size = input_features.size(0)\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            input_features = input_features.cuda()\n",
    "            input_seqs = input_seqs.cuda()\n",
    "            input_seqs_mask = input_seqs_mask.cuda()\n",
    "            input_seqs_pad_mask = input_seqs_pad_mask.cuda()\n",
    "            target_seqs = target_seqs.cuda()\n",
    "        \n",
    "        ctc_output, output, memory, decoder_output = model(input_features, input_seqs, input_seqs_mask, input_seqs_pad_mask)\n",
    "        \n",
    "        total += (target_seqs.view(-1) != token2id['<pad>']).sum().item()\n",
    "        _, predicted = torch.max(output.view(-1, opts.ntoken).data, 1)\n",
    "        correct += ((predicted == target_seqs.view(-1)) * (target_seqs.view(-1) != token2id['<pad>'])).sum().item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ce_loss = ce_criterion(output.view(-1, opts.ntoken), target_seqs.view(-1))\n",
    "        \n",
    "        ctc_output = ctc_output.permute(1, 0, 2).log_softmax(2)\n",
    "        \n",
    "        input_lengths = torch.full(size=(ctc_output.size(1),), fill_value=ctc_output.size(0), dtype=torch.long)\n",
    "        target_lengths = lens\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            input_lengths = input_lengths.cuda()\n",
    "            target_lengths = target_lengths.cuda()\n",
    "        \n",
    "        ctc_loss = ctc_criterion(ctc_output, target_seqs, input_lengths, target_lengths)\n",
    "        \n",
    "        loss = opts.ce_weight*ce_loss + opts.ctc_weight*ctc_loss\n",
    "        \n",
    "        celoss_tracker.append(ce_loss.item()*batch_size)\n",
    "        ctcloss_tracker.append(ctc_loss.item()*batch_size)\n",
    "        loss_tracker.append(loss.item()*batch_size)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        pbar_train.update(1)\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    time_tracker.append(time.time())\n",
    "    log_msg = \"{} | Epoch {:d}/{:d} | Mean CE / CTC / ALL Loss {:5.2f} / {:5.2f} / {:5.2f} | acc {:5.5f} % | time cost {:d} s\"\\\n",
    "            .format('train'.upper(), epoch, opts.num_epochs, \\\n",
    "                    np.mean(celoss_tracker), np.mean(ctcloss_tracker), np.mean(loss_tracker), \\\n",
    "                    float(correct)/float(total)*100, int(time_tracker[-1] - time_tracker[-2]))\n",
    "    print(log_msg)\n",
    "    log2file(str(experiment_trainlog), log_msg)\n",
    "    \n",
    "    loss_tracker = []\n",
    "    celoss_tracker = []\n",
    "    ctcloss_tracker = []\n",
    "    time_tracker = []\n",
    "    time_tracker.append(time.time())\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    \n",
    "    for iteration, batch in enumerate(dev_iter):\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        name, input_features, text, token, input_seqs, input_seqs_mask, input_seqs_pad_mask, target_seqs, lens = batch\n",
    "        \n",
    "        batch_size = input_features.size(0)\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            input_features = input_features.cuda()\n",
    "            input_seqs = input_seqs.cuda()\n",
    "            input_seqs_mask = input_seqs_mask.cuda()\n",
    "            input_seqs_pad_mask = input_seqs_pad_mask.cuda()\n",
    "            target_seqs = target_seqs.cuda()\n",
    "        \n",
    "        ctc_output, output, memory, decoder_output = model(input_features, input_seqs, input_seqs_mask, input_seqs_pad_mask)\n",
    "        \n",
    "        total += (target_seqs.view(-1) != token2id['<pad>']).sum().item()\n",
    "        _, predicted = torch.max(output.view(-1, opts.ntoken).data, 1)\n",
    "        correct += ((predicted == target_seqs.view(-1)) * (target_seqs.view(-1) != token2id['<pad>'])).sum().item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ce_loss = ce_criterion(output.view(-1, opts.ntoken), target_seqs.view(-1))\n",
    "        \n",
    "        ctc_output = ctc_output.permute(1, 0, 2).log_softmax(2)\n",
    "        \n",
    "        input_lengths = torch.full(size=(ctc_output.size(1),), fill_value=ctc_output.size(0), dtype=torch.long)\n",
    "        target_lengths = lens\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            input_lengths = input_lengths.cuda()\n",
    "            target_lengths = target_lengths.cuda()\n",
    "        \n",
    "        ctc_loss = ctc_criterion(ctc_output, target_seqs, input_lengths, target_lengths)\n",
    "        \n",
    "        loss = opts.ce_weight*ce_loss + opts.ctc_weight*ctc_loss\n",
    "        \n",
    "        celoss_tracker.append(ce_loss.item()*batch_size)\n",
    "        ctcloss_tracker.append(ctc_loss.item()*batch_size)\n",
    "        loss_tracker.append(loss.item()*batch_size)\n",
    "        \n",
    "        pbar_dev.update(1)\n",
    "        \n",
    "    time_tracker.append(time.time())\n",
    "    log_msg = \"{} | Epoch {:d}/{:d} | Mean CE / CTC / ALL Loss {:5.2f} / {:5.2f} / {:5.2f} | acc {:5.5f} % | time cost {:d} s\"\\\n",
    "            .format('dev  '.upper(), epoch, opts.num_epochs, \\\n",
    "                    np.mean(celoss_tracker), np.mean(ctcloss_tracker), np.mean(loss_tracker), \\\n",
    "                    float(correct)/float(total)*100, int(time_tracker[-1] - time_tracker[-2]))\n",
    "    print(log_msg)\n",
    "    log2file(str(experiment_trainlog), log_msg)\n",
    "    \n",
    "    loss_tracker = []\n",
    "    celoss_tracker = []\n",
    "    ctcloss_tracker = []\n",
    "    time_tracker = []\n",
    "    time_tracker.append(time.time())\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for iteration, batch in enumerate(test_iter):\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        name, input_features, text, token, input_seqs, input_seqs_mask, input_seqs_pad_mask, target_seqs, lens = batch\n",
    "        \n",
    "        batch_size = input_features.size(0)\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            input_features = input_features.cuda()\n",
    "            input_seqs = input_seqs.cuda()\n",
    "            input_seqs_mask = input_seqs_mask.cuda()\n",
    "            input_seqs_pad_mask = input_seqs_pad_mask.cuda()\n",
    "            target_seqs = target_seqs.cuda()\n",
    "        \n",
    "        ctc_output, output, memory, decoder_output = model(input_features, input_seqs, input_seqs_mask, input_seqs_pad_mask)\n",
    "        \n",
    "        total += (target_seqs.view(-1) != token2id['<pad>']).sum().item()\n",
    "        _, predicted = torch.max(output.view(-1, opts.ntoken).data, 1)\n",
    "        correct += ((predicted == target_seqs.view(-1)) * (target_seqs.view(-1) != token2id['<pad>'])).sum().item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ce_loss = ce_criterion(output.view(-1, opts.ntoken), target_seqs.view(-1))\n",
    "        \n",
    "        ctc_output = ctc_output.permute(1, 0, 2).log_softmax(2)\n",
    "        \n",
    "        input_lengths = torch.full(size=(ctc_output.size(1),), fill_value=ctc_output.size(0), dtype=torch.long)\n",
    "        target_lengths = lens\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            input_lengths = input_lengths.cuda()\n",
    "            target_lengths = target_lengths.cuda()\n",
    "        \n",
    "        ctc_loss = ctc_criterion(ctc_output, target_seqs, input_lengths, target_lengths)\n",
    "        \n",
    "        loss = opts.ce_weight*ce_loss + opts.ctc_weight*ctc_loss\n",
    "        \n",
    "        celoss_tracker.append(ce_loss.item()*batch_size)\n",
    "        ctcloss_tracker.append(ctc_loss.item()*batch_size)\n",
    "        loss_tracker.append(loss.item()*batch_size)\n",
    "        \n",
    "        pbar_test.update(1)\n",
    "        \n",
    "    time_tracker.append(time.time())\n",
    "    log_msg = \"{} | Epoch {:d}/{:d} | Mean CE / CTC / ALL Loss {:5.2f} / {:5.2f} / {:5.2f} | acc {:5.5f} % | time cost {:d} s\"\\\n",
    "            .format('test '.upper(), epoch, opts.num_epochs, \\\n",
    "                    np.mean(celoss_tracker), np.mean(ctcloss_tracker), np.mean(loss_tracker), \\\n",
    "                    float(correct)/float(total)*100, int(time_tracker[-1] - time_tracker[-2]))\n",
    "    print(log_msg)\n",
    "    log2file(str(experiment_trainlog), log_msg)\n",
    "    \n",
    "    checkpoint = {\n",
    "        \"net\": model.state_dict(),\n",
    "        'optimizer':optimizer.state_dict(),\n",
    "        \"epoch\": epoch\n",
    "    }\n",
    "    \n",
    "    torch.save(checkpoint, experiment_dir / 'epoch_{}.ckpt'.format(epoch))\n",
    "    \n",
    "    log_msg = '='*50\n",
    "    print(log_msg)\n",
    "    log2file(str(experiment_trainlog), log_msg)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc_output.shape, target_seqs.shape, input_lengths.shape, target_lengths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc_output[:, 0, :][0].log_softmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/mnt/disk3/m10615110/jupyter/yesno.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = Test_Model(opts.ntoken, opts.ninp, opts.nhead, opts.nhid, opts.nlayers_enc, opts.nlayers_dec, opts.feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model.load_state_dict(torch.load('/mnt/disk3/m10615110/jupyter/yesno.mdl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class error_stats:\n",
    "    def __init__(self):\n",
    "        self.ins_num = 0 \n",
    "        self.del_num = 0\n",
    "        self.sub_num = 0\n",
    "        self.total_cost = 0\n",
    "        \n",
    "# ref=['聽', '說', '馬', '上', '就', '要', '放', '假', '了']\n",
    "# hyp=['你', '聽', '說', '要', '放', '假', '了']\n",
    "\n",
    "def wer(ref, hyp):\n",
    "    N = len(ref)\n",
    "    e = []\n",
    "    for i in range(len(ref)+1):\n",
    "        e.append(error_stats())\n",
    "    cur_e = []\n",
    "    for i in range(len(ref)+1):\n",
    "        cur_e.append(error_stats)\n",
    "\n",
    "    for i in range(len(e)):\n",
    "        e[i].ins_num = 0\n",
    "        e[i].sub_num = 0\n",
    "        e[i].del_num = i\n",
    "        e[i].total_cost = i\n",
    "\n",
    "    for hyp_index in range(1, len(hyp)+1):\n",
    "        cur_e[0] = copy.copy(e[0])\n",
    "\n",
    "        cur_e[0].ins_num+=1\n",
    "        cur_e[0].total_cost+=1\n",
    "        for ref_index in range(1, len(ref)+1):\n",
    "            ins_err = e[ref_index].total_cost + 1\n",
    "            #print(cur_e[ref_index-1].total_cost)\n",
    "            del_err = cur_e[ref_index-1].total_cost + 1\n",
    "            sub_err = e[ref_index-1].total_cost\n",
    "            #print(ins_err, del_err, sub_err)\n",
    "            #print(e[0].total_cost)\n",
    "            if hyp[hyp_index-1] != ref[ref_index-1]:\n",
    "                sub_err+=1\n",
    "            #print(ins_err, del_err, sub_err)\n",
    "            if sub_err < ins_err and sub_err < del_err:\n",
    "                cur_e[ref_index] = copy.copy(e[ref_index-1])\n",
    "                \n",
    "                if hyp[hyp_index-1] != ref[ref_index-1]:\n",
    "                    cur_e[ref_index].sub_num+=1\n",
    "                cur_e[ref_index].total_cost = sub_err\n",
    "            elif del_err < ins_err:\n",
    "                cur_e[ref_index] = copy.copy(cur_e[ref_index-1])\n",
    "\n",
    "                cur_e[ref_index].total_cost = del_err\n",
    "                cur_e[ref_index].del_num+=1\n",
    "            else:\n",
    "                cur_e[ref_index] = copy.copy(e[ref_index])\n",
    "\n",
    "                cur_e[ref_index].total_cost = ins_err\n",
    "                cur_e[ref_index].ins_num+=1\n",
    "        e = cur_e.copy()\n",
    "\n",
    "    ref_index = len(e)-1\n",
    "    Ins = e[ref_index].ins_num\n",
    "    Del = e[ref_index].del_num\n",
    "    Sub = e[ref_index].sub_num\n",
    "    Cost = e[ref_index].total_cost\n",
    "    #print(Ins, Del, Sub, Cost)\n",
    "    return Ins, Del, Sub, Cost, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm_notebook(total = len(test_iter))\n",
    "\n",
    "nbests = []\n",
    "refs = []\n",
    "\n",
    "for batch in test_iter:\n",
    "    \n",
    "    name, input_features, text, token, input_seqs, input_seqs_mask, target_seqs, lens = batch\n",
    "    \n",
    "    t_model.eval()\n",
    "    \n",
    "    len_limit = int(input_features.size(1) * 0.1)\n",
    "    \n",
    "    \n",
    "    nbest, beams = t_model(input_features, len_limit)\n",
    "    \n",
    "    if len(nbest) == 0:\n",
    "        nbest = beams\n",
    "        \n",
    "    nbest.sort(key=lambda x:x[1])\n",
    "    nbest = nbest[::-1]\n",
    "        \n",
    "    nbests.append(nbest)\n",
    "    refs.append(token)\n",
    "    \n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(refs), len(nbests))\n",
    "\n",
    "totalN = 0\n",
    "totalIns = 0\n",
    "totalDel = 0\n",
    "totalSub = 0\n",
    "\n",
    "for ref, nbest in zip(refs, nbests):\n",
    "    \n",
    "    nbest.sort(key=lambda x:x[1])\n",
    "    nbest = nbest[::-1]\n",
    "    hyp = [id2token[token] for token in nbest[0][0]]\n",
    "    ref = ref[0]    \n",
    "    \n",
    "    Ins, Del, Sub, Cost, N = wer(ref[1:-1], hyp[1:-1])\n",
    "    totalN += N\n",
    "    totalIns += Ins\n",
    "    totalDel += Del\n",
    "    totalSub += Sub\n",
    "    \n",
    "    \n",
    "print(totalN, totalIns, totalDel, totalSub)\n",
    "\n",
    "print('wer : {}'.format((totalIns+totalDel+totalSub)/totalN*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
